{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar100.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4lf57WFMO0W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "687e8116-fd6d-4b82-8271-96ac95944985"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ck2JkDdJnqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "52757d68-b68a-43aa-f554-4da6b92006c4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Aug 27 17:16:44 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAXXZ6F0KbSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential,Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, BatchNormalization, Activation, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import UpSampling2D, AveragePooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import LearningRateSchedule\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvW6qMlrJsMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "2047050d-9c61-4511-f36a-6ccbd6d73e8b"
      },
      "source": [
        "(x_train,y_train), (x_test,y_test) = cifar100.load_data()\n",
        "\n",
        "x_val, y_val = x_train[40000:], y_train[40000:]\n",
        "x_train, y_train = x_train[:40000], y_train[:40000]\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_val = x_val / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
        "x_val = x_val.reshape(x_val.shape[0], 32, 32, 3)\n",
        "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 100)\n",
        "y_val = keras.utils.to_categorical(y_val, 100)\n",
        "y_test = keras.utils.to_categorical(y_test, 100)\n",
        "\n",
        "\n",
        "pretrained_model = tf.keras.applications.ResNet50V2(include_top=False, \n",
        "                                                    weights='imagenet', \n",
        "                                                    input_tensor=None, \n",
        "                                                    input_shape=(128, 128, 3), \n",
        "                                                    classifier_activation='softmax')\n",
        "\n",
        "model = Sequential([Input(shape=(32,32,3)),\n",
        "                    UpSampling2D(),\n",
        "                    UpSampling2D(),\n",
        "                    pretrained_model,\n",
        "                    GlobalAveragePooling2D(),\n",
        "                    Dropout(0.5),\n",
        "                    Dense(512, activation='relu'),\n",
        "                    BatchNormalization(),\n",
        "                    Dense(num_classes, activation='softmax')\n",
        "                    ])\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 9s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 2s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "up_sampling2d (UpSampling2D) (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 128, 128, 3)       0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 4, 4, 2048)        23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               51300     \n",
            "=================================================================\n",
            "Total params: 24,665,188\n",
            "Trainable params: 24,619,748\n",
            "Non-trainable params: 45,440\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYBO2ZQgq12S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 100\n",
        "epochs = 90\n",
        "lrate = 1e-3"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2te3HZrVXUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "54a499f6-903d-4ea1-83de-61ddf7cb0efb"
      },
      "source": [
        "datagen = ImageDataGenerator(rotation_range=30, \n",
        "                             width_shift_range=0.1, \n",
        "                             height_shift_range=0.1,\n",
        "                             horizontal_flip=True, \n",
        "                             fill_mode='nearest')\n",
        "datagen.fit(x_train)\n",
        "opt = keras.optimizers.Adam(learning_rate=lrate)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer= opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "H = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), \n",
        "                        steps_per_epoch=len(x_train)/128,\n",
        "                        validation_data=(x_val, y_val),\n",
        "                        epochs=epochs)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "312/312 [==============================] - 73s 233ms/step - loss: 4.8272 - accuracy: 0.0121 - val_loss: 4.5780 - val_accuracy: 0.0161\n",
            "Epoch 2/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 4.5619 - accuracy: 0.0248 - val_loss: 4.4943 - val_accuracy: 0.0447\n",
            "Epoch 3/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 4.4811 - accuracy: 0.0439 - val_loss: 4.3804 - val_accuracy: 0.0690\n",
            "Epoch 4/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 4.3860 - accuracy: 0.0618 - val_loss: 4.2552 - val_accuracy: 0.0916\n",
            "Epoch 5/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 4.2692 - accuracy: 0.0816 - val_loss: 4.1030 - val_accuracy: 0.1210\n",
            "Epoch 6/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 4.1392 - accuracy: 0.1052 - val_loss: 3.9275 - val_accuracy: 0.1505\n",
            "Epoch 7/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 3.9786 - accuracy: 0.1346 - val_loss: 3.7582 - val_accuracy: 0.1903\n",
            "Epoch 8/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 3.7895 - accuracy: 0.1660 - val_loss: 3.4460 - val_accuracy: 0.2359\n",
            "Epoch 9/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 3.5891 - accuracy: 0.1979 - val_loss: 3.2605 - val_accuracy: 0.2723\n",
            "Epoch 10/90\n",
            "312/312 [==============================] - 71s 227ms/step - loss: 3.3802 - accuracy: 0.2333 - val_loss: 3.0002 - val_accuracy: 0.3060\n",
            "Epoch 11/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 3.1928 - accuracy: 0.2592 - val_loss: 2.8133 - val_accuracy: 0.3340\n",
            "Epoch 12/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 3.0093 - accuracy: 0.2922 - val_loss: 2.6071 - val_accuracy: 0.3754\n",
            "Epoch 13/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 2.8367 - accuracy: 0.3164 - val_loss: 2.4516 - val_accuracy: 0.4034\n",
            "Epoch 14/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 2.6651 - accuracy: 0.3507 - val_loss: 2.2651 - val_accuracy: 0.4392\n",
            "Epoch 15/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 2.5255 - accuracy: 0.3740 - val_loss: 2.1342 - val_accuracy: 0.4578\n",
            "Epoch 16/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 2.3768 - accuracy: 0.4032 - val_loss: 2.0199 - val_accuracy: 0.4793\n",
            "Epoch 17/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 2.2706 - accuracy: 0.4234 - val_loss: 1.8628 - val_accuracy: 0.5024\n",
            "Epoch 18/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 2.1453 - accuracy: 0.4456 - val_loss: 1.7480 - val_accuracy: 0.5289\n",
            "Epoch 19/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 2.0660 - accuracy: 0.4611 - val_loss: 1.6769 - val_accuracy: 0.5420\n",
            "Epoch 20/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.9840 - accuracy: 0.4765 - val_loss: 1.6000 - val_accuracy: 0.5591\n",
            "Epoch 21/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.9042 - accuracy: 0.4912 - val_loss: 1.5658 - val_accuracy: 0.5655\n",
            "Epoch 22/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.8397 - accuracy: 0.5074 - val_loss: 1.5022 - val_accuracy: 0.5807\n",
            "Epoch 23/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.7734 - accuracy: 0.5202 - val_loss: 1.4800 - val_accuracy: 0.5852\n",
            "Epoch 24/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.7238 - accuracy: 0.5338 - val_loss: 1.4220 - val_accuracy: 0.5923\n",
            "Epoch 25/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.6846 - accuracy: 0.5415 - val_loss: 1.3815 - val_accuracy: 0.6079\n",
            "Epoch 26/90\n",
            "312/312 [==============================] - 71s 227ms/step - loss: 1.6278 - accuracy: 0.5574 - val_loss: 1.3381 - val_accuracy: 0.6193\n",
            "Epoch 27/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.5801 - accuracy: 0.5680 - val_loss: 1.3165 - val_accuracy: 0.6256\n",
            "Epoch 28/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.5485 - accuracy: 0.5748 - val_loss: 1.2763 - val_accuracy: 0.6361\n",
            "Epoch 29/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.5031 - accuracy: 0.5852 - val_loss: 1.2576 - val_accuracy: 0.6397\n",
            "Epoch 30/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.4760 - accuracy: 0.5890 - val_loss: 1.2369 - val_accuracy: 0.6460\n",
            "Epoch 31/90\n",
            "312/312 [==============================] - 71s 227ms/step - loss: 1.4273 - accuracy: 0.6022 - val_loss: 1.2379 - val_accuracy: 0.6470\n",
            "Epoch 32/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.4190 - accuracy: 0.6046 - val_loss: 1.1879 - val_accuracy: 0.6585\n",
            "Epoch 33/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.3880 - accuracy: 0.6136 - val_loss: 1.1816 - val_accuracy: 0.6610\n",
            "Epoch 34/90\n",
            "312/312 [==============================] - 71s 229ms/step - loss: 1.3563 - accuracy: 0.6235 - val_loss: 1.1506 - val_accuracy: 0.6695\n",
            "Epoch 35/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.3376 - accuracy: 0.6255 - val_loss: 1.1362 - val_accuracy: 0.6690\n",
            "Epoch 36/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.3090 - accuracy: 0.6346 - val_loss: 1.1188 - val_accuracy: 0.6745\n",
            "Epoch 37/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.2759 - accuracy: 0.6419 - val_loss: 1.1178 - val_accuracy: 0.6767\n",
            "Epoch 38/90\n",
            "312/312 [==============================] - 71s 229ms/step - loss: 1.2502 - accuracy: 0.6474 - val_loss: 1.1020 - val_accuracy: 0.6845\n",
            "Epoch 39/90\n",
            "312/312 [==============================] - 71s 229ms/step - loss: 1.2361 - accuracy: 0.6482 - val_loss: 1.0850 - val_accuracy: 0.6857\n",
            "Epoch 40/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.2081 - accuracy: 0.6594 - val_loss: 1.0743 - val_accuracy: 0.6889\n",
            "Epoch 41/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.1989 - accuracy: 0.6606 - val_loss: 1.0630 - val_accuracy: 0.6949\n",
            "Epoch 42/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.1879 - accuracy: 0.6646 - val_loss: 1.0544 - val_accuracy: 0.6972\n",
            "Epoch 43/90\n",
            "312/312 [==============================] - 71s 229ms/step - loss: 1.1555 - accuracy: 0.6702 - val_loss: 1.0383 - val_accuracy: 0.7013\n",
            "Epoch 44/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.1382 - accuracy: 0.6761 - val_loss: 1.0397 - val_accuracy: 0.7035\n",
            "Epoch 45/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.1177 - accuracy: 0.6801 - val_loss: 1.0187 - val_accuracy: 0.7047\n",
            "Epoch 46/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.1145 - accuracy: 0.6803 - val_loss: 1.0218 - val_accuracy: 0.7046\n",
            "Epoch 47/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.0915 - accuracy: 0.6869 - val_loss: 1.0076 - val_accuracy: 0.7120\n",
            "Epoch 48/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.0790 - accuracy: 0.6881 - val_loss: 0.9985 - val_accuracy: 0.7118\n",
            "Epoch 49/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.0606 - accuracy: 0.6954 - val_loss: 0.9892 - val_accuracy: 0.7172\n",
            "Epoch 50/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.0380 - accuracy: 0.7021 - val_loss: 0.9894 - val_accuracy: 0.7160\n",
            "Epoch 51/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.0231 - accuracy: 0.7045 - val_loss: 0.9890 - val_accuracy: 0.7151\n",
            "Epoch 52/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.0137 - accuracy: 0.7095 - val_loss: 0.9883 - val_accuracy: 0.7189\n",
            "Epoch 53/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 1.0071 - accuracy: 0.7079 - val_loss: 0.9638 - val_accuracy: 0.7223\n",
            "Epoch 54/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.9830 - accuracy: 0.7147 - val_loss: 0.9790 - val_accuracy: 0.7193\n",
            "Epoch 55/90\n",
            "312/312 [==============================] - 71s 227ms/step - loss: 0.9729 - accuracy: 0.7178 - val_loss: 0.9825 - val_accuracy: 0.7192\n",
            "Epoch 56/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.9643 - accuracy: 0.7196 - val_loss: 0.9497 - val_accuracy: 0.7285\n",
            "Epoch 57/90\n",
            "312/312 [==============================] - 71s 227ms/step - loss: 0.9567 - accuracy: 0.7200 - val_loss: 0.9469 - val_accuracy: 0.7293\n",
            "Epoch 58/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.9404 - accuracy: 0.7274 - val_loss: 0.9631 - val_accuracy: 0.7267\n",
            "Epoch 59/90\n",
            "312/312 [==============================] - 71s 227ms/step - loss: 0.9320 - accuracy: 0.7293 - val_loss: 0.9428 - val_accuracy: 0.7310\n",
            "Epoch 60/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.9221 - accuracy: 0.7354 - val_loss: 0.9517 - val_accuracy: 0.7283\n",
            "Epoch 61/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.8970 - accuracy: 0.7385 - val_loss: 0.9400 - val_accuracy: 0.7318\n",
            "Epoch 62/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.8983 - accuracy: 0.7387 - val_loss: 0.9355 - val_accuracy: 0.7351\n",
            "Epoch 63/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.8791 - accuracy: 0.7433 - val_loss: 0.9590 - val_accuracy: 0.7301\n",
            "Epoch 64/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.8681 - accuracy: 0.7456 - val_loss: 0.9288 - val_accuracy: 0.7355\n",
            "Epoch 65/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.8567 - accuracy: 0.7487 - val_loss: 0.9282 - val_accuracy: 0.7371\n",
            "Epoch 66/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.8555 - accuracy: 0.7499 - val_loss: 0.9093 - val_accuracy: 0.7420\n",
            "Epoch 67/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.8394 - accuracy: 0.7519 - val_loss: 0.9227 - val_accuracy: 0.7405\n",
            "Epoch 68/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.8267 - accuracy: 0.7582 - val_loss: 0.9187 - val_accuracy: 0.7372\n",
            "Epoch 69/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.8253 - accuracy: 0.7605 - val_loss: 0.9288 - val_accuracy: 0.7397\n",
            "Epoch 70/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.8066 - accuracy: 0.7626 - val_loss: 0.9270 - val_accuracy: 0.7372\n",
            "Epoch 71/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.8035 - accuracy: 0.7642 - val_loss: 0.9010 - val_accuracy: 0.7485\n",
            "Epoch 72/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.7914 - accuracy: 0.7648 - val_loss: 0.9035 - val_accuracy: 0.7464\n",
            "Epoch 73/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.7799 - accuracy: 0.7684 - val_loss: 0.8940 - val_accuracy: 0.7488\n",
            "Epoch 74/90\n",
            "312/312 [==============================] - 71s 229ms/step - loss: 0.7766 - accuracy: 0.7705 - val_loss: 0.9024 - val_accuracy: 0.7461\n",
            "Epoch 75/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.7727 - accuracy: 0.7711 - val_loss: 0.9053 - val_accuracy: 0.7452\n",
            "Epoch 76/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.7626 - accuracy: 0.7757 - val_loss: 0.8993 - val_accuracy: 0.7467\n",
            "Epoch 77/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.7541 - accuracy: 0.7758 - val_loss: 0.9048 - val_accuracy: 0.7469\n",
            "Epoch 78/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.7425 - accuracy: 0.7790 - val_loss: 0.9007 - val_accuracy: 0.7460\n",
            "Epoch 79/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.7308 - accuracy: 0.7820 - val_loss: 0.9052 - val_accuracy: 0.7466\n",
            "Epoch 80/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.7234 - accuracy: 0.7842 - val_loss: 0.8914 - val_accuracy: 0.7520\n",
            "Epoch 81/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.7224 - accuracy: 0.7855 - val_loss: 0.9008 - val_accuracy: 0.7517\n",
            "Epoch 82/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.7132 - accuracy: 0.7891 - val_loss: 0.8880 - val_accuracy: 0.7532\n",
            "Epoch 83/90\n",
            "312/312 [==============================] - 71s 227ms/step - loss: 0.6981 - accuracy: 0.7931 - val_loss: 0.8903 - val_accuracy: 0.7541\n",
            "Epoch 84/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.6916 - accuracy: 0.7946 - val_loss: 0.8884 - val_accuracy: 0.7559\n",
            "Epoch 85/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.6889 - accuracy: 0.7934 - val_loss: 0.8914 - val_accuracy: 0.7547\n",
            "Epoch 86/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.6800 - accuracy: 0.7988 - val_loss: 0.8965 - val_accuracy: 0.7544\n",
            "Epoch 87/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.6754 - accuracy: 0.7976 - val_loss: 0.8894 - val_accuracy: 0.7535\n",
            "Epoch 88/90\n",
            "312/312 [==============================] - 71s 227ms/step - loss: 0.6621 - accuracy: 0.8021 - val_loss: 0.8803 - val_accuracy: 0.7560\n",
            "Epoch 89/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.6505 - accuracy: 0.8040 - val_loss: 0.8827 - val_accuracy: 0.7597\n",
            "Epoch 90/90\n",
            "312/312 [==============================] - 71s 228ms/step - loss: 0.6462 - accuracy: 0.8059 - val_loss: 0.9202 - val_accuracy: 0.7483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gerxnNEIz3qg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "ed361589-2708-44a5-ed74-432418cc1f8b"
      },
      "source": [
        "score = model.evaluate(x_test, y_test)\n",
        "print(f'Test loss: {score[0]:.4f}')\n",
        "print(f'Test accuracy: {score[1]:.4f}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 7s 24ms/step - loss: 0.8834 - accuracy: 0.7538\n",
            "Test loss: 0.8834\n",
            "Test accuracy: 0.7538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_q66kLFoYgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/model.h5')"
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}